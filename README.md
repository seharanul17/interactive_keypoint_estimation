<div><h1 align="center">Morphology-Aware Interactive Keypoint Estimation (MICCAI 2022)</h1></div>

<div align="center">
  <a href="https://sites.google.com/view/jinhee-kim">Jinhee Kim*</a> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
  <a href="https://github.com/ts-kim/">Taesung Kim*</a> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
  Taewoo Kim<br>
  seharanul17@kaist.ac.kr &emsp;&emsp;&emsp; zkm1989@kaist.ac.kr &emsp;&emsp;&emsp; specia1ktu@kaist.ac.kr<br>
  KAIST &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; KAIST &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; KAIST<br><br>

  <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
  Dong-Wook Kim &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
  Byungduk Ahn<br>
  &emsp;jchoo@kaist.ac.kr &emsp;&emsp;&emsp; dwkim9393@naver.com &emsp;&emsp;&emsp; bdspeed@naver.com<br>
  &emsp;&emsp; KAIST &emsp;&emsp;&emsp;&emsp; Korea University Anam Hospital &emsp;&emsp; Papa's dental clinic<br>
  
  In-Seok Song &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Yoon-Ji Kim<br>&emsp;
  densis@korea.ac.kr &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; yn0331@gmail.com<br>
  Korea University Anam Hospital &emsp;&emsp;&emsp; <span>Asan Medical Center</span>&emsp;
</div>

<div align="center">
*Denotes Equal Contribution
</div>
<br>
<img align="center" src="./video.gif" width="1000px" height="500px">

<div>

<h3>Link</h3>
<a href="https://sites.google.com/site/jaegulchoo/"><b>[Paper]</b></a>
&emsp;
<a href="https://youtu.be/Z5gtLviQ_TU"><b>[Video]</b></a>
&emsp;
<a href="https://github.com/seharanul17/interactive_keypoint_estimation"><b>[Code]</b></a>


<h3>Abstract</h3>

Diagnosis based on medical images, such as X-ray images, often involves manual annotation of anatomical keypoints. However, this process involves significant human efforts and can thus be a bottleneck in the diagnostic process. To fully automate this procedure, deep-learningbased methods have been widely proposed and have achieved high performance in detecting keypoints in medical images. However, these methods still have clinical limitations: accuracy cannot be guaranteed for all cases, and it is necessary for doctors to double-check all predictions of models.
In response, we propose a novel deep neural network that, given an Xray image, automatically detects and refines the anatomical keypoints through a user-interactive system in which doctors can fix mispredicted keypoints with fewer clicks than needed during manual revision. Using our own collected data and the publicly available AASCE dataset, we demonstrate the effectiveness of the proposed method in reducing the annotation costs via extensive quantitative and qualitative results.



<h3>Poster</h3>
<img align="center" src="./online_poster_miccai22.png" width="1000px" height="500px">



</div>


